# -*- coding: utf-8 -*-
"""K Medoids_ETE_PA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IzhL63cVeSLc4qt-f0Zb47lvsgMEFkcN

**K-Medoids Clustering**

K-Medoids is similar to K-Means but uses actual data points (medoids) as cluster centers, making it robust to noise and outliers.

Working:
*   Initialize k medoids randomly.
*   Assign each data point to the closest medoid.
*   Update medoids by selecting the most central point (minimizing the sum
  of distances) in each cluster.
*   Repeat until convergence.
"""

!pip install scikit-learn-extra

# Import necessary libraries
import numpy as np
from sklearn_extra.cluster import KMedoids
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.datasets import make_blobs

# Generate synthetic dataset
def generate_data(n_samples=300, n_features=2, centers=3, random_state=42):
    data, labels = make_blobs(n_samples=n_samples, n_features=n_features, centers=centers, random_state=random_state)
    return data, labels

# Evaluation metrics
def evaluate_clustering(data, clustering_labels):
    sil_score = silhouette_score(data, clustering_labels)
    db_score = davies_bouldin_score(data, clustering_labels)
    ch_score = calinski_harabasz_score(data, clustering_labels)
    return sil_score, db_score, ch_score

# K-Medoids clustering
def kmedoids_clustering(data, n_clusters):
    kmedoids = KMedoids(n_clusters=n_clusters, random_state=42)
    kmedoids_labels = kmedoids.fit_predict(data)
    return kmedoids, kmedoids_labels

# Main script for K-Medoids
if __name__ == "__main__":
    # Generate data
    data, true_labels = generate_data()

    # Apply K-Medoids
    kmedoids, kmedoids_labels = kmedoids_clustering(data, n_clusters=3)

    # Evaluate K-Medoids
    kmedoids_scores = evaluate_clustering(data, kmedoids_labels)
    print("K-Medoids Evaluation (Silhouette, Davies-Bouldin, Calinski-Harabasz):", kmedoids_scores)

